#!/usr/bin/env python
# coding: utf-8

import numpy as np

y_predicted = np.array([1,1,0,0,1])
y_true = np.array([0.20,0.8,1,0.7,0.8])




# # MAE 

def mae(y_true, y_predicted): #2 parameters
    total_error = 0,#define "total error" variable
    for yt,yp in zip (y_true, y_predicted): #Loop through 2 lists
        print(yt,yp)

mae(y_true, y_predicted)
#We have the two values

def mae(y_true, y_predicted): #2 parameters
    total_error = 0,#define "total error" variable
    for yt,yp in zip (y_true, y_predicted):  #Loop through 2 lists
        total_error += np.abs(yt-yp)  #Add the difference to "total error" in each iteration
    print ('Total Error', total_error)
    mae = total_error/len(y_true)
    print ('MAE is equal to', mae)
    return mae

mae(y_true, y_predicted)


# # MSE

def mse(y_true, y_predicted): #2 parameters
    total_s_error = 0,#define "total_s_error" variable
    for yt,yp in zip (y_true, y_predicted):  #Loop through 2 lists
        total_s_error += np.abs(yt-yp)*2  #Add the difference to "total_s_error" in each iteration
    print ('Total Error', total_s_error)
    mse = total_s_error/len(y_true)
    print ('MSE is equal to', mse)
    return (mse)

mse(y_true, y_predicted)




# # Log

# Note: We can't define log([0]), so we need to transform the values
# - We need to have a value very close to 0 but not 0

np.log([0])

epsilon = 1e-10

y_predicted

# We need to replace the value of 1 with another value very close to 1, same for 0, with a value very close to 0

y_predicted2 = [max(i,epsilon)for i in y_predicted]
# We will remplace a value of 0 with a value very close to 0
y_predicted2

y_predicted2 = [min(i,1-epsilon)for i in y_predicted2]
#We remplace the value of 1 by another very close to 1
y_predicted2

np.log(y_predicted2)
#Now we will not have errors in the formula "log(0)"


def mlog_loss(y_true, y_predicted): #2 parameters
    y_predicted2 = [max(i,epsilon)for i in y_predicted]
    y_predicted2 = [min(i,1-epsilon)for i in y_predicted2]
    y_predicted2 = np.array(y_predicted2)
    return -np.mean(y_true*np.log(y_predicted2)+(1-y_true)*np.log(1-y_predicted2))

mlog_loss(y_true, y_predicted)

