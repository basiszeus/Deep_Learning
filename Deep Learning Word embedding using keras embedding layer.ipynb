{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cd3a12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.functional_saver has been moved to tensorflow.python.checkpoint.functional_saver. The old module will be deleted in version 2.11.\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.saving.checkpoint_options has been moved to tensorflow.python.checkpoint.checkpoint_options. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699a125",
   "metadata": {},
   "source": [
    "SSM REVIEWS Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e35a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = ['nice business school',\n",
    "          'I learned a lot about big data and AI, very good experience',\n",
    "          'bad experience',\n",
    "          ' it was ok, but I do note recommanded to anyone',\n",
    "          'very nice shcool, I learned a lot and I made friends with whom I started projects',\n",
    "          'Need more improvement']\n",
    "sentiment = np.array([1,1,0,0,1,0]) #1 for good sentiment and 0 for bad one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14f03526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 23, 6]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The first thing to do is convert it to OHE\n",
    "#each review will be converted into a random unique number depending on which does not exceed your vocabulary size.\n",
    "\n",
    "one_hot(\"nice business school\",50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3b86a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you see for nice we have 12, for business 23 and for school 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c9462f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12, 23, 6], [8, 33, 10, 19, 6, 1, 18, 17, 40, 20, 29, 38], [21, 38], [29, 41, 48, 47, 8, 35, 16, 25, 9, 17], [20, 12, 15, 8, 33, 10, 19, 17, 8, 8, 14, 3, 9, 8, 47, 31], [26, 45, 19]]\n"
     ]
    }
   ],
   "source": [
    "#let's encode all the reviews now\n",
    "vocab_size = 50\n",
    "encoded_reviews = [one_hot(i, vocab_size)for i in reviews]\n",
    "print(encoded_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd4ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to use padding because we have different length for reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "313fa67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 23,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 8, 33, 10, 19,  6,  1, 18, 17, 40, 20, 29, 38,  0,  0,  0,  0],\n",
       "       [21, 38,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [29, 41, 48, 47,  8, 35, 16, 25,  9, 17,  0,  0,  0,  0,  0,  0],\n",
       "       [20, 12, 15,  8, 33, 10, 19, 17,  8,  8, 14,  3,  9,  8, 47, 31],\n",
       "       [26, 45, 19,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 16\n",
    "padded_reviews = pad_sequences(encoded_reviews, maxlen=max_length, padding='post')\n",
    "#Padding post mean that you need to pad the review toward the end\n",
    "padded_reviews\n",
    "#They have equal size now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43114def",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeded_vector_size = 4 #The features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c35a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating my model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embeded_vector_size, input_length=max_length,name=\"embedding\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#The first argument is your vocabulary size, then the embeded vector, the inputs length (features) and give it a name.\n",
    "#The second layer is flattened all the vector into one.\n",
    "#Then you apply sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6494446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining X and y to train the model:\n",
    "\n",
    "X = padded_reviews #Inputs\n",
    "y = sentiment #Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a70cab95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 16, 4)             200       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265\n",
      "Trainable params: 265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "#Binary_crossentropy because we only have 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffaca8d",
   "metadata": {},
   "source": [
    "- The maximum penalty is 16\n",
    "- The sinking vector is 4\n",
    "- Flatten is 64 (4*16)\n",
    "- Dense is 1 because we have a neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afb8dca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2122fb3c4f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7920e23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 131ms/step - loss: 0.5609 - accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8333333134651184"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(X, y)\n",
    "accuracy\n",
    "#83% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ea56541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.get_layer('embedding').get_weights()[0]\n",
    "len(weights) #it's 50 because of the vocabulary size \n",
    "#This method gives you all the weights in the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1065ce87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04734632,  0.00258898,  0.02213548, -0.03280065], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[12] #4 because of the features for the word nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c45a48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11190153,  0.12063858,  0.01715918, -0.10536227], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's compare it with the words good\n",
    "weights[29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "941695fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normally they should be similar, but due to the lack of data, the similarity is not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c73661d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
